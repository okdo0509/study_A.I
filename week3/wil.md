**Weekly I learned!**  
=================  
## **1.이미지 분류의 정의와 활용**  
* 이미지 분류란? 컴퓨터가 주어진 이미지를 보고 특징을 추출하여 이미지가 어떤 카테고리에 속하는지 판단하는 것입니다.  
* 카테고리에 개수의 따라 이진분류와 다중분류로 나눌 수 있습니다. 학습에는 지도 학습 뿐만아니라 비지도 학습과 같은 다른 학습으로도 구현할 수 있습니다
* ex) 네이버 식물 검색, 당근 마켓 중고 물품 분류  
## **2.이미지 데이터의 구조**  
1. 픽셀(Pixel,화소): 화면을 구성하는 가장 최소의 단위입니다. 픽셀의 수가 많아질수록 해상도가 높다고 합니다.  
2. 채널(Channel): 픽셀의 색을 표현하는 것을 채널이라하고 채널이 하나일 경우 흑,백을 통해 흑백이미지를 구현하고 채널이 3개일 경우 RGB를 통해 컬러 이미지를 구현합니다.  
3. 해상도(Resolution): 이미지를 구현하기 위해 사용된 픽셀의 수 입니다. 픽셀의 수가 많을 수록 해상도는 높아집니다.  
## **3.기본적인 이미지 분류 접근 방식**  
### Raw-pixel을 이용한 비교 ###  
* 이미지의 픽셀 값을 직접 비교하여 유사성을 판단하는 것  
    1. 모든 이미지를 같은 크기로 조정합니다.(ex)$ N \times N $ 픽셀)
    2. 각 이미지를 1차원 벡터(열벡터or행벡터)로 펼칩니다.  
    3. 새로운 이미지와 기존 이미지들의 벡터 간 거리를 계산합니다.  
        * 벡터 간 거리를 계산하는 방법  
            1. $ L_1 = |x_2 - x_1| + |y_2-y_1|$
            2. $ L_2 = \sqrt {(x_2 - x_1)^2+(y_2-y_1)^2}  $  
    4. 가장 거리가 가까운 이미지의 클래스로 새 이미지를 분류합니다.  
## **4.선형분류기**  
* 선형분류(Linear Classifier)란? y = Wx + b로 표시되는 선형 함수로 데이터를 분류하는 모델. 즉, 선을 통해 두 가지 케이스로 분류하는 것입니다.  
두 그룹을 가장 잘 나누는 선을 찾는 방법으로는 퍼셉트론이 존재합니다.  
* 선형 분류를 위해 이미지의 픽셀과 채널을 열행렬로 만든 후(32px $ \times $ 32px의 컬러 이미지의 경우 3027 $ \times $ 1 행렬) 가중치 행렬을 곱하고 편향 행렬을 더해 클래스 마다의 값을 구하고 그 값이 가장 높은 클래스로 분류하는 것입니다.  
* 단, 물체의 특성이 아닌 각 픽셀을 기준으로 차이를 비교하기 때문에 boxed된 사진이나 픽셀을 조금만 이동시켜도 구분하지 못합니다.  
* 시점 차이, 조명의 변화, 다양한 자세, 일부가 가려진 사진등 다양한 데이터 셋에서도 정확히 분류할 수 있는 강건한 (Robust) 분류기를 만들어야합니다.  
## **5.CNN(합성곱 신경망)** 
* 위의 이미지 분류는 1차원으로 펼처서 처리하는 FNN방식으로 인접 픽셀간의 상관관계가 무시되어 이미지를 벡터화하는 과정에서 정보손실 발생합니다. 하지만 CNN방식은 이미지의 2차원 구조를 유지하며 분석하는 방식입니다.  
* CNN의 과정으로는 필터를 사용하여 feature map을 얻습니다. feature map을 얻기 위해 Convolution Layer(A Convolutional Layer = convolution + activation)를 생성합니다.  
    * convolution: n $ \times $ n 행렬을 만들어 각각의 요소에 값을 넣은 후 같은 위치끼리 곱을 한 후 모든 요소들의 합을 하나의 요소로 만드는 것  
    * activation: 활성화 함수로 각 층에서 더 복잡하고 추상적인 특징을 학습을 하게 해주는 역활을 합니다. 딥러닝 네트워크에 비선형성을 추가해 줍니다.  
        * 대표적인 함수: Sigmoid(가장 마지막 layer에 주로 사용),ReLU(은닉층에 주로 사용)  
* Feature map의 크기를 줄이기 위해 Pooling Layer를 생성합니다.  
    * MAX Pooling: n $ \times $ n 행렬 내에서 가장 큰 값을 추출합니다.  
    * Average Poolingn $ \times $ n 행렬 내 요소들의 평균값을 추출합니다.  
* 이러한 과정을 한번 혹은 여러번 반복한 후 FNN을 이용하여 최종 분류를 시작합니다.(이 과정에서 특징들이 이미 공간적 관계를 가지고 있으므로 1차원으로 펼처도 특징을 유지할 수 있습니다.)  
* FNN을 통해 분류한 값들을 softmax함수를 이용하여 클래스에 해당할 확률을 0과1사이의 값으로 정규화를 진행합니다.(이때, 모든 값의 합은 1입니다.)
